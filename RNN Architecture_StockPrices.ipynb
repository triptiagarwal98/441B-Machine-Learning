{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9sYcDE-qV7z"
   },
   "source": [
    "# Building and Tuning an RNN Model with LSTM to predict if stock price moves up or down the following trading day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dJuZDx9qWeM"
   },
   "source": [
    "## 1.) Importing asset price from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3bcwJb4rp93",
    "outputId": "6488930e-f8a4-4ecb-a3ce-cc73d755672d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#picking Amazon stock\n",
    "#time period: post 2010\n",
    "stock_data = yf.download(\"AMZN\", start=\"2010-01-01\", end=\"2022-12-31\")\n",
    "\n",
    "# Preprocess data\n",
    "# scaling using pct_change as it is time series data\n",
    "scaled_data = np.array(stock_data[\"Close\"].pct_change().dropna()).reshape(-1,1)   #reshape(-1,1) means 1 col,u figure out rows\n",
    "\n",
    "# Split data into training and test sets\n",
    "training_data_len = int(len(scaled_data) * 0.8)\n",
    "train_data = scaled_data[0:training_data_len, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04 00:00:00-05:00</th>\n",
       "      <td>6.812500</td>\n",
       "      <td>6.830500</td>\n",
       "      <td>6.657000</td>\n",
       "      <td>6.695000</td>\n",
       "      <td>6.695000</td>\n",
       "      <td>151998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05 00:00:00-05:00</th>\n",
       "      <td>6.671500</td>\n",
       "      <td>6.774000</td>\n",
       "      <td>6.590500</td>\n",
       "      <td>6.734500</td>\n",
       "      <td>6.734500</td>\n",
       "      <td>177038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06 00:00:00-05:00</th>\n",
       "      <td>6.730000</td>\n",
       "      <td>6.736500</td>\n",
       "      <td>6.582500</td>\n",
       "      <td>6.612500</td>\n",
       "      <td>6.612500</td>\n",
       "      <td>143576000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07 00:00:00-05:00</th>\n",
       "      <td>6.600500</td>\n",
       "      <td>6.616000</td>\n",
       "      <td>6.440000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>220604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08 00:00:00-05:00</th>\n",
       "      <td>6.528000</td>\n",
       "      <td>6.684000</td>\n",
       "      <td>6.451500</td>\n",
       "      <td>6.676000</td>\n",
       "      <td>6.676000</td>\n",
       "      <td>196610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23 00:00:00-05:00</th>\n",
       "      <td>83.250000</td>\n",
       "      <td>85.779999</td>\n",
       "      <td>82.930000</td>\n",
       "      <td>85.250000</td>\n",
       "      <td>85.250000</td>\n",
       "      <td>57433700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27 00:00:00-05:00</th>\n",
       "      <td>84.970001</td>\n",
       "      <td>85.349998</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.040001</td>\n",
       "      <td>83.040001</td>\n",
       "      <td>57284000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 00:00:00-05:00</th>\n",
       "      <td>82.800003</td>\n",
       "      <td>83.480003</td>\n",
       "      <td>81.690002</td>\n",
       "      <td>81.820000</td>\n",
       "      <td>81.820000</td>\n",
       "      <td>58228600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29 00:00:00-05:00</th>\n",
       "      <td>82.870003</td>\n",
       "      <td>84.550003</td>\n",
       "      <td>82.550003</td>\n",
       "      <td>84.180000</td>\n",
       "      <td>84.180000</td>\n",
       "      <td>54995900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 00:00:00-05:00</th>\n",
       "      <td>83.120003</td>\n",
       "      <td>84.050003</td>\n",
       "      <td>82.470001</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>62330000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3272 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2010-01-04 00:00:00-05:00   6.812500   6.830500   6.657000   6.695000   \n",
       "2010-01-05 00:00:00-05:00   6.671500   6.774000   6.590500   6.734500   \n",
       "2010-01-06 00:00:00-05:00   6.730000   6.736500   6.582500   6.612500   \n",
       "2010-01-07 00:00:00-05:00   6.600500   6.616000   6.440000   6.500000   \n",
       "2010-01-08 00:00:00-05:00   6.528000   6.684000   6.451500   6.676000   \n",
       "...                              ...        ...        ...        ...   \n",
       "2022-12-23 00:00:00-05:00  83.250000  85.779999  82.930000  85.250000   \n",
       "2022-12-27 00:00:00-05:00  84.970001  85.349998  83.000000  83.040001   \n",
       "2022-12-28 00:00:00-05:00  82.800003  83.480003  81.690002  81.820000   \n",
       "2022-12-29 00:00:00-05:00  82.870003  84.550003  82.550003  84.180000   \n",
       "2022-12-30 00:00:00-05:00  83.120003  84.050003  82.470001  84.000000   \n",
       "\n",
       "                           Adj Close     Volume  \n",
       "Date                                             \n",
       "2010-01-04 00:00:00-05:00   6.695000  151998000  \n",
       "2010-01-05 00:00:00-05:00   6.734500  177038000  \n",
       "2010-01-06 00:00:00-05:00   6.612500  143576000  \n",
       "2010-01-07 00:00:00-05:00   6.500000  220604000  \n",
       "2010-01-08 00:00:00-05:00   6.676000  196610000  \n",
       "...                              ...        ...  \n",
       "2022-12-23 00:00:00-05:00  85.250000   57433700  \n",
       "2022-12-27 00:00:00-05:00  83.040001   57284000  \n",
       "2022-12-28 00:00:00-05:00  81.820000   58228600  \n",
       "2022-12-29 00:00:00-05:00  84.180000   54995900  \n",
       "2022-12-30 00:00:00-05:00  84.000000   62330000  \n",
       "\n",
       "[3272 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foHoGy9hq3_o"
   },
   "source": [
    "## 2.) Creating x_train/y_train data so that the RNN uses percentage change data to make a binary forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00589989],\n",
       "       [-0.01811563],\n",
       "       [-0.01701326],\n",
       "       ...,\n",
       "       [-0.00402982],\n",
       "       [-0.00616361],\n",
       "       [-0.00473604]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "input_size = 5   #depicts the number of time lags   #so using a week (5 trading days)\n",
    "for i in range(input_size, len(train_data)):\n",
    "    x_train.append(train_data[i-input_size:i, 0])\n",
    "    y_train.append(np.where(train_data[i, 0] > 0, 1,0))\n",
    "\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "#reshaping input because RNN model needs 3rd dimension too (input_dim)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))    #3rd dimension is 1 since univariate TS\n",
    "#shape is -- num_samples, input_size, input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1390\n",
       "0    1221\n",
       "dtype: int64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()   #shows that the output data is almost balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an RNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "82/82 [==============================] - 5s 7ms/step - loss: 0.6918 - accuracy: 0.5205\n",
      "Epoch 2/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6915 - accuracy: 0.5324\n",
      "Epoch 3/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6915 - accuracy: 0.5324\n",
      "Epoch 4/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6915 - accuracy: 0.5324\n",
      "Epoch 5/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 6/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 7/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6915 - accuracy: 0.5324\n",
      "Epoch 8/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 9/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6914 - accuracy: 0.5324\n",
      "Epoch 10/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 11/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6912 - accuracy: 0.5324\n",
      "Epoch 12/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6918 - accuracy: 0.5324\n",
      "Epoch 13/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 14/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6911 - accuracy: 0.5324\n",
      "Epoch 15/15\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.6912 - accuracy: 0.5324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d3fc6a7d30>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#adding LSTM layer\n",
    "model.add(LSTM(50, return_sequences=False, input_shape=(x_train.shape[1], 1)))\n",
    "#LSTM(no.of neurons--hyperparameter-to be tuned, useful to stack multiple lstm layers, (no.of time steps, no.of features))\n",
    "\n",
    "#adding another LSTM layer\n",
    "#model.add(LSTM(150, return_sequences=False))\n",
    "\n",
    "model.add(Dense(25))\n",
    "#model.add(Dropout(0.3))   #to prevent overfitting\n",
    "model.add(Dense(1, activation='sigmoid'))       #output   \n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])   \n",
    "#adam implies adaptive learning rates\n",
    "\n",
    "model.fit(x_train, y_train, epochs=15)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53033024],\n",
       "       [0.53118724],\n",
       "       [0.52905756],\n",
       "       ...,\n",
       "       [0.5299061 ],\n",
       "       [0.5297766 ],\n",
       "       [0.52986085]], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the output to binary to see if stock goes up or down the next day\n",
    "y_pred_binary = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows that the output has binary outcomes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFhO9vMjsWPk"
   },
   "source": [
    "## 3.) Testing the model: Comparing insample Accurracy, insample random walk assumption Accuracy, Out of sample Accuracy and out of sample random walk assumption Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = scaled_data[training_data_len - input_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(input_size, len(test_data)):\n",
    "    x_test.append(test_data[i-input_size:i, 0])\n",
    "    y_test.append(np.where(test_data[i, 0] > 0, 1,0))\n",
    "\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))    #3rd dimension is 1 since univariate TS\n",
    "#shape is -- num_samples, input_size, input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 3ms/step\n",
      "The in sample model accuracy is: 0.46763692072003066\n",
      "The in sample random walk model accuracy is: 0.4957854406130268\n"
     ]
    }
   ],
   "source": [
    "#in sample accuracy\n",
    "predictions = model.predict(x_train)\n",
    "y_pred_binary = (predictions > 0.588).astype(int)\n",
    "insample_acc = accuracy_score(y_train, y_pred_binary)\n",
    "\n",
    "#in sample random walk accuracy\n",
    "#y_train[:-1]   #actual\n",
    "#y_train[1:]    #predicted\n",
    "insample_rand_acc = accuracy_score(y_train[:-1], y_train[1:])\n",
    "print(\"The in sample model accuracy is:\", insample_acc)\n",
    "print(\"The in sample random walk model accuracy is:\", insample_rand_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step\n",
      "The out of sample model accuracy is: 0.49770992366412214\n",
      "The out of sample random walk model accuracy is: 0.5198776758409785\n"
     ]
    }
   ],
   "source": [
    "#out sample accuracy\n",
    "oos_predictions = model.predict(x_test)\n",
    "oos_y_pred_binary = (oos_predictions > 0.588).astype(int)\n",
    "outsample_acc = accuracy_score(y_test, oos_y_pred_binary)\n",
    "\n",
    "#out sample random walk accuracy\n",
    "#y_test[:-1]   #actual\n",
    "#y_test[1:]    #predicted\n",
    "outsample_rand_acc = accuracy_score(y_test[:-1], y_test[1:])\n",
    "\n",
    "print(\"The out of sample model accuracy is:\", outsample_acc)\n",
    "print(\"The out of sample random walk model accuracy is:\", outsample_rand_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'In_Acc':insample_acc, 'In_RW_Acc':insample_rand_acc, 'Out_Acc':outsample_acc, 'Out_RW_Acc':outsample_rand_acc}\n",
    "metrics = list(data.keys())\n",
    "values = list(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcEAAAEYCAYAAAAkik0PAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgBklEQVR4nO3dfXBU1eH/8c+Sh00IJCLRALqE8CAEUp+SFhOaxoDGUqetoy0pKPgArTFKjamikXHAVA21itEZA0ZBxAKmFpxpp2lt6hAMRC2miWMLCj7QjbghJmgCaDeQnN8f/Nh+1yyQTVaTeN6vmTvjPfece8+9Z+KHc+/dXYcxxggAAAsN6e8OAADQXwhBAIC1CEEAgLUIQQCAtQhBAIC1CEEAgLUIQQCAtQhBAIC1CEEAgLUIQQCAtXoVgmVlZUpKSlJUVJRSU1NVU1Nzyvper1dLly5VYmKinE6nJkyYoLVr1/aqwwAAhEp4sA0qKipUUFCgsrIyzZgxQ0899ZRmz56tXbt2aezYsQHbzJkzRwcOHNCaNWs0ceJENTc369ixY33uPAAAfeEI9gu0p0+frosvvlirVq3ylSUnJ+uqq65SSUlJt/p//etf9bOf/UwffPCBzjzzzL73GACAEAlqJtjR0aG6ujrdc889fuU5OTmqra0N2OaPf/yj0tLS9PDDD+v5559XTEyMfvSjH+nXv/61oqOjA7bxer3yer2+9a6uLh08eFAjR46Uw+EIpssAgG8IY4wOHTqkMWPGaMiQ0LzSElQItrS0qLOzUwkJCX7lCQkJampqCtjmgw8+0Pbt2xUVFaWXXnpJLS0tys/P18GDB0/6XLCkpET3339/MF0DAFiisbFR5557bkj2FfQzQUndZmPGmJPO0Lq6uuRwOLRhwwbFxcVJklauXKmf/OQnevLJJwPOBouKilRYWOhbb2tr09ixY9XY2KjY2NjedBkAMMi1t7fL5XJp+PDhIdtnUCEYHx+vsLCwbrO+5ubmbrPDE0aPHq1zzjnHF4DS8WeIxhh99NFHmjRpUrc2TqdTTqezW3lsbCwhCACWC+VjsaBuqkZGRio1NVVVVVV+5VVVVcrIyAjYZsaMGfr44491+PBhX9mePXs0ZMiQkE1nAQDojaCfLBYWFuqZZ57R2rVrtXv3bt1xxx1yu93Ky8uTdPxW5oIFC3z1582bp5EjR+rGG2/Url279Oqrr+quu+7STTfddNIXYwAA+DoE/UwwNzdXra2tKi4ulsfjUUpKiiorK5WYmChJ8ng8crvdvvrDhg1TVVWVFi9erLS0NI0cOVJz5szRAw88ELqzAACgF4L+nGB/aG9vV1xcnNra2ngmCACW+iqygO8OBQBYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWCu8vzsAAPh6jLvnz/16/H0rruzX4wfCTBAAYC1CEABgLUIQAGCtXoVgWVmZkpKSFBUVpdTUVNXU1Jy0bnV1tRwOR7flnXfe6XWnAQAIhaBDsKKiQgUFBVq6dKnq6+uVmZmp2bNny+12n7Ldu+++K4/H41smTZrU604DABAKQYfgypUrtXDhQi1atEjJyckqLS2Vy+XSqlWrTtnu7LPP1qhRo3xLWFhYrzsNAEAoBBWCHR0dqqurU05Ojl95Tk6OamtrT9n2oosu0ujRozVr1ixt3br1lHW9Xq/a29v9FgAAQi2oEGxpaVFnZ6cSEhL8yhMSEtTU1BSwzejRo1VeXq7Nmzdry5Ytmjx5smbNmqVXX331pMcpKSlRXFycb3G5XMF0EwCAHunVh+UdDoffujGmW9kJkydP1uTJk33r6enpamxs1COPPKLvfe97AdsUFRWpsLDQt97e3k4QWoYP9Q4ejBUGs6BmgvHx8QoLC+s262tubu42OzyVSy65RHv37j3pdqfTqdjYWL8FAIBQCyoEIyMjlZqaqqqqKr/yqqoqZWRk9Hg/9fX1Gj16dDCHBgAg5IK+HVpYWKj58+crLS1N6enpKi8vl9vtVl5enqTjtzL379+v9evXS5JKS0s1btw4TZs2TR0dHfrd736nzZs3a/PmzaE9EwAAghR0CObm5qq1tVXFxcXyeDxKSUlRZWWlEhMTJUkej8fvM4MdHR268847tX//fkVHR2vatGn685//rB/84AehOwsAAHqhVy/G5OfnKz8/P+C2devW+a0vWbJES5Ys6c1hAAD4SvHdoQAAaxGCAABrEYIAAGsRggAAaxGCAABr9ert0MGKr3cCAPxfzAQBANYiBAEA1iIEAQDWIgQBANYiBAEA1iIEAQDWIgQBANYiBAEA1iIEAQDWIgQBANYiBAEA1iIEAQDWIgQBANYiBAEA1iIEAQDWIgQBANYiBAEA1iIEAQDWIgQBANYiBAEA1iIEAQDW6lUIlpWVKSkpSVFRUUpNTVVNTU2P2u3YsUPh4eG68MILe3NYAABCKugQrKioUEFBgZYuXar6+nplZmZq9uzZcrvdp2zX1tamBQsWaNasWb3uLAAAoRR0CK5cuVILFy7UokWLlJycrNLSUrlcLq1ateqU7W6++WbNmzdP6enpve4sAAChFFQIdnR0qK6uTjk5OX7lOTk5qq2tPWm7Z599Vu+//76WLVvWo+N4vV61t7f7LQAAhFpQIdjS0qLOzk4lJCT4lSckJKipqSlgm7179+qee+7Rhg0bFB4e3qPjlJSUKC4uzre4XK5gugkAQI/06sUYh8Pht26M6VYmSZ2dnZo3b57uv/9+nXfeeT3ef1FRkdra2nxLY2Njb7oJAMAp9Wxq9v/Fx8crLCys26yvubm52+xQkg4dOqQ333xT9fX1uu222yRJXV1dMsYoPDxcf/vb3zRz5sxu7ZxOp5xOZzBdAwAgaEHNBCMjI5Wamqqqqiq/8qqqKmVkZHSrHxsbq7ffflsNDQ2+JS8vT5MnT1ZDQ4OmT5/et94DANAHQc0EJamwsFDz589XWlqa0tPTVV5eLrfbrby8PEnHb2Xu379f69ev15AhQ5SSkuLX/uyzz1ZUVFS3cgAAvm5Bh2Bubq5aW1tVXFwsj8ejlJQUVVZWKjExUZLk8XhO+5lBAAAGgqBDUJLy8/OVn58fcNu6detO2Xb58uVavnx5bw4LAEBI8d2hAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAa/UqBMvKypSUlKSoqCilpqaqpqbmpHW3b9+uGTNmaOTIkYqOjtaUKVP02GOP9brDAACESniwDSoqKlRQUKCysjLNmDFDTz31lGbPnq1du3Zp7Nix3erHxMTotttu0/nnn6+YmBht375dN998s2JiYvSLX/wiJCcBAEBvBD0TXLlypRYuXKhFixYpOTlZpaWlcrlcWrVqVcD6F110kebOnatp06Zp3Lhxuu6663TFFVeccvYIAMDXIagQ7OjoUF1dnXJycvzKc3JyVFtb26N91NfXq7a2VllZWcEcGgCAkAvqdmhLS4s6OzuVkJDgV56QkKCmpqZTtj333HP1ySef6NixY1q+fLkWLVp00rper1der9e33t7eHkw3AQDokV69GONwOPzWjTHdyr6spqZGb775plavXq3S0lJt2rTppHVLSkoUFxfnW1wuV2+6CQDAKQU1E4yPj1dYWFi3WV9zc3O32eGXJSUlSZK+9a1v6cCBA1q+fLnmzp0bsG5RUZEKCwt96+3t7QQhACDkgpoJRkZGKjU1VVVVVX7lVVVVysjI6PF+jDF+tzu/zOl0KjY21m8BACDUgv6IRGFhoebPn6+0tDSlp6ervLxcbrdbeXl5ko7P4vbv36/169dLkp588kmNHTtWU6ZMkXT8c4OPPPKIFi9eHMLTAAAgeEGHYG5urlpbW1VcXCyPx6OUlBRVVlYqMTFRkuTxeOR2u331u7q6VFRUpA8//FDh4eGaMGGCVqxYoZtvvjl0ZwEAQC8EHYKSlJ+fr/z8/IDb1q1b57e+ePFiZn0AgAGJ7w4FAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFiLEAQAWIsQBABYixAEAFirVyFYVlampKQkRUVFKTU1VTU1NSetu2XLFl1++eU666yzFBsbq/T0dL388su97jAAAKESdAhWVFSooKBAS5cuVX19vTIzMzV79my53e6A9V999VVdfvnlqqysVF1dnbKzs/XDH/5Q9fX1fe48AAB9EXQIrly5UgsXLtSiRYuUnJys0tJSuVwurVq1KmD90tJSLVmyRN/+9rc1adIkPfTQQ5o0aZL+9Kc/9bnzAAD0RVAh2NHRobq6OuXk5PiV5+TkqLa2tkf76Orq0qFDh3TmmWeetI7X61V7e7vfAgBAqAUVgi0tLers7FRCQoJfeUJCgpqamnq0j0cffVRHjhzRnDlzTlqnpKREcXFxvsXlcgXTTQAAeqRXL8Y4HA6/dWNMt7JANm3apOXLl6uiokJnn332SesVFRWpra3NtzQ2NvammwAAnFJ4MJXj4+MVFhbWbdbX3NzcbXb4ZRUVFVq4cKFefPFFXXbZZaes63Q65XQ6g+kaAABBC2omGBkZqdTUVFVVVfmVV1VVKSMj46TtNm3apBtuuEEbN27UlVde2bueAgAQYkHNBCWpsLBQ8+fPV1pamtLT01VeXi632628vDxJx29l7t+/X+vXr5d0PAAXLFigxx9/XJdccolvFhkdHa24uLgQngoAAMEJOgRzc3PV2tqq4uJieTwepaSkqLKyUomJiZIkj8fj95nBp556SseOHdOtt96qW2+91Vd+/fXXa926dX0/AwAAeinoEJSk/Px85efnB9z25WCrrq7uzSEAAPjK8d2hAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABrEYIAAGsRggAAaxGCAABr9SoEy8rKlJSUpKioKKWmpqqmpuakdT0ej+bNm6fJkydryJAhKigo6G1fAQAIqaBDsKKiQgUFBVq6dKnq6+uVmZmp2bNny+12B6zv9Xp11llnaenSpbrgggv63GEAAEIl6BBcuXKlFi5cqEWLFik5OVmlpaVyuVxatWpVwPrjxo3T448/rgULFiguLq7PHQYAIFSCCsGOjg7V1dUpJyfHrzwnJ0e1tbUh65TX61V7e7vfAgBAqAUVgi0tLers7FRCQoJfeUJCgpqamkLWqZKSEsXFxfkWl8sVsn0DAHBCr16McTgcfuvGmG5lfVFUVKS2tjbf0tjYGLJ9AwBwQngwlePj4xUWFtZt1tfc3NxtdtgXTqdTTqczZPsDACCQoGaCkZGRSk1NVVVVlV95VVWVMjIyQtoxAAC+akHNBCWpsLBQ8+fPV1pamtLT01VeXi632628vDxJx29l7t+/X+vXr/e1aWhokCQdPnxYn3zyiRoaGhQZGampU6eG5iwAAOiFoEMwNzdXra2tKi4ulsfjUUpKiiorK5WYmCjp+Ifjv/yZwYsuusj333V1ddq4caMSExO1b9++vvUeAIA+CDoEJSk/P1/5+fkBt61bt65bmTGmN4cBAOArxXeHAgCsRQgCAKxFCAIArEUIAgCsRQgCAKxFCAIArEUIAgCsRQgCAKxFCAIArEUIAgCsRQgCAKxFCAIArEUIAgCsRQgCAKxFCAIArEUIAgCsRQgCAKxFCAIArEUIAgCsRQgCAKxFCAIArEUIAgCsRQgCAKxFCAIArEUIAgCsRQgCAKxFCAIArNWrECwrK1NSUpKioqKUmpqqmpqaU9bftm2bUlNTFRUVpfHjx2v16tW96iwAAKEUdAhWVFSooKBAS5cuVX19vTIzMzV79my53e6A9T/88EP94Ac/UGZmpurr63Xvvffql7/8pTZv3tznzgMA0BdBh+DKlSu1cOFCLVq0SMnJySotLZXL5dKqVasC1l+9erXGjh2r0tJSJScna9GiRbrpppv0yCOP9LnzAAD0RXgwlTs6OlRXV6d77rnHrzwnJ0e1tbUB27z22mvKycnxK7viiiu0Zs0aHT16VBEREd3aeL1eeb1e33pbW5skqb29PZjudtPl/bxP7fuqr/23CWM1eDBWg8dgH6sT7Y0xoeiOpCBDsKWlRZ2dnUpISPArT0hIUFNTU8A2TU1NAesfO3ZMLS0tGj16dLc2JSUluv/++7uVu1yuYLo74MSV9ncP0FOM1eDBWA0eoRqrQ4cOKS4uLiT7CioET3A4HH7rxphuZaerH6j8hKKiIhUWFvrWu7q6dPDgQY0cOfKUx/kqtbe3y+VyqbGxUbGxsf3SB/QMYzV4MFaDx0AYK2OMDh06pDFjxoRsn0GFYHx8vMLCwrrN+pqbm7vN9k4YNWpUwPrh4eEaOXJkwDZOp1NOp9Ov7Iwzzgimq1+Z2NhY/lgHCcZq8GCsBo/+HqtQzQBPCOrFmMjISKWmpqqqqsqvvKqqShkZGQHbpKend6v/t7/9TWlpaQGfBwIA8HUJ+u3QwsJCPfPMM1q7dq12796tO+64Q263W3l5eZKO38pcsGCBr35eXp7+85//qLCwULt379batWu1Zs0a3XnnnaE7CwAAeiHoZ4K5ublqbW1VcXGxPB6PUlJSVFlZqcTEREmSx+Px+8xgUlKSKisrdccdd+jJJ5/UmDFj9MQTT+iaa64J3Vl8DZxOp5YtW9btNi0GHsZq8GCsBo9v6lg5TCjfNQUAYBDhu0MBANYiBAEA1iIEAQDWIgQBANb6RofgDTfcoKuuuiqk+3zooYcUFhamFStWhHS/g10or/W4cePkcDjkcDgUHR2tKVOm6Le//a3vm4ZWr16t4cOH69ixY742hw8fVkREhDIzM/32VVNTI4fDoT179vT4+IzxcY2NjVq4cKHGjBmjyMhIJSYm6vbbb1dra2uP97Fv3z45HA41NDQEffyPPvpIkZGRmjJlStBtB6P+ut7Lly/3/b0NGTJEY8aM0bXXXqvGxkZJ//vbqqio8GuXm5srh8Oh999/3698woQJuvfee3t8/P4e5290CH4Vnn32WS1ZskRr167t7658o534CM7u3bt155136t5771V5ebkkKTs7W4cPH9abb77pq19TU6NRo0Zp586d+vzz/31JcHV1tcaMGaPzzjuvx8dmjKUPPvhAaWlp2rNnjzZt2qT33ntPq1ev1iuvvKL09HQdPHjwK+/DunXrNGfOHH3++efasWPHV368/tTf13vatGnyeDz66KOPVFFRobfffltz5syRJA0bNkxpaWnaunWrX5tt27bJ5XL5lX/00Uf64IMPlJ2d3eNj9/s4m2+w66+/3vz4xz82xhiTlZVlFi9ebO666y4zYsQIk5CQYJYtWxbU/qqrq80555xjOjo6zJgxY8y2bdv8tnd2dpoVK1aYCRMmmMjISONyucwDDzzg297Y2Ghyc3PNiBEjzNChQ01qaqp5/fXX+3qaA0Ior3ViYqJ57LHH/Mouvvhic/XVV/vWx4wZY0pKSnzrS5YsMbfeequZOnWqqaqq8pXPnDnTXHvttT0+NmN83Pe//31z7rnnms8//9yv3OPxmKFDh5q8vDxjjDGSzEsvveRXJy4uzjz77LO+7f93ycrK6tHxu7q6zPjx481f//pXc/fdd5sbb7yxW53t27eb733veyY6OtqcccYZJicnxxw8eNAYc/pxGmj683ovW7bMXHDBBX5lTzzxhJFk2trajDHGFBUVmcmTJ/u279q1y8TGxpqSkhK/v6/169ebiIgIc+TIkR6d90AYZ6tmgs8995xiYmL0xhtv6OGHH1ZxcXG3r3Q7lTVr1mju3LmKiIjQ3LlztWbNGr/tRUVF+s1vfqP77rtPu3bt0saNG33fqXr48GFlZWXp448/1h//+Ee99dZbWrJkibq6ukJ6jgNFX6/1CcYYVVdXa/fu3X5fs3fppZf6/Qt069atuvTSS5WVleUr7+jo0GuvvRbUv0oZY+ngwYN6+eWXlZ+fr+joaL9to0aN0rXXXquKiooe/ZzNP/7xD0nS3//+d3k8Hm3ZsqVHfdi6das+//xzXXbZZZo/f75+//vf69ChQ77tDQ0NmjVrlqZNm6bXXntN27dv1w9/+EN1dnZKOvU4DTQD4Xr/X01NTdqyZYvCwsIUFhYm6fjdl3fffVcej0fS8fHJzMzUzJkzVV1d7Wu7detWTZ8+XUOHDu3RsQbEOAcVmYPMl2cn3/3ud/22f/vb3zZ33313j/bV1tZmhg4dahoaGowxxtTX15uhQ4f6/qXU3t5unE6nefrppwO2f+qpp8zw4cNNa2trL89mYAvltU5MTDSRkZEmJibGREREGEkmKirK7Nixw1envLzcxMTEmKNHj5r29nYTHh5uDhw4YF544QWTkZFhjDFm27ZtRpJ5//33e3Rcxvi4119/PeCM44SVK1caSebAgQOnnZl8+OGHRpKpr68Pqg/z5s0zBQUFvvULLrjA77rPnTvXzJgxI2Db043TQNPf13vZsmVmyJAhJiYmxkRHR/tmkb/85S99dY4cOWIiIiLMxo0bjTHG/PSnPzUPP/ywOXr0qBk2bJjZs2ePMcaYpKQkc9999/X42ANhnK2aCZ5//vl+66NHj1Zzc3OP2m7cuFHjx4/XBRdcIEm68MILNX78eL3wwguSpN27d8vr9WrWrFkB2zc0NOiiiy7SmWee2YczGDz6cq0l6a677lJDQ4O2bdum7OxsLV261O9L2rOzs3XkyBHt3LlTNTU1Ou+883T22WcrKytLO3fu1JEjR1RdXa2xY8dq/PjxPTomY9wz5jQ/hdZXn332mbZs2aLrrrvOV3bdddf5PaM9MUMI5HTjNNh81ddbkiZPnqyGhgbt3LlTDz74oC688EI9+OCDvu1Dhw7Vd77zHd+sb9u2bbr00ksVHh6uGTNmqLq6Wm63Wx9++KFmzpzZo2MOlHHu1e8JDlZf/tUKh8PR41tVa9eu1b///W+Fh//vknV1dWnNmjX6xS9+0e02xpedbvs3TV+utXT8Z7smTpyoiRMnavPmzZo4caIuueQSXXbZZZKkiRMn6txzz9XWrVv16aefKisrS9Lx20dJSUnasWOHtm7d2uM/SIkxPmHixIlyOBzatWtXwDd+33nnHY0YMULx8fFyOBzdbtMdPXq0T8ffuHGj/vvf/2r69Om+MmOMurq6tGvXLk2dOvWU13qwjUN/X2/p+C8ETZw4UdLxl2T27t2rW265Rc8//7yvTnZ2tioqKvTvf/9bX3zxhS6++GJJ8j2CiIyMVFRUlC655JIeHXOgjLNVM8Heevvtt/Xmm2+qurpaDQ0NvuXVV1/Vzp079a9//UuTJk1SdHS0XnnllYD7OP/889XQ0PC1vFX3TTNixAgtXrxYd955p9//ALKzs1VdXa3q6mpdeumlvvKsrCy9/PLLev3113v8PJAx/p+RI0fq8ssvV1lZmb744gu/bU1NTdqwYYPv9fizzjrL95xIkvbu3ev3dm5kZKQk+Z7h9MSaNWv0q1/9ym8c3nrrLWVnZ/tmCeeff/5Jx+F04zTQ9Pf1DuS+++7Tpk2b9M9//tNXlp2drb1792rjxo367ne/63temJWV5fs7TE9PV1RUVI+OMWDGuU83Uwe4Lz+nuv322/22//jHPzbXX3/9afdz++23m+nTpwfclpGR4bunvXz5cjNixAjz3HPPmffee8+89tpr5plnnjHGGOP1es15551nMjMzzfbt2837779v/vCHP5ja2tpen99AEqprbUzgt0Obm5tNVFSUefHFF31la9euNdHR0SY8PNw0NTX5yn/3u9+Z4cOHG0nG7Xb36JiMsb89e/aY+Ph4k5mZabZt22bcbrf5y1/+YlJSUsykSZN8zz1/9rOfmeTkZFNXV2d27txpZs6caSIiInzPqI4ePWqio6PNAw88YJqamsxnn312yuPW19cbSWb37t3dtpWXl5uzzjrLdHR0mHfffddERkaaW265xbz11ltm9+7dpqyszHzyySfGmFOP00DUX9fbmMBvhxpjzNVXX22uvPJK3/oXX3xhnE6nGT58uFmxYoWvvKOjwwwdOtQMHz7cFBcX9+h8B9I4E4Kn+R+z1+s1I0eONA8//HDA7Y8++qiJj483Xq/XdHZ2mgceeMAkJiaaiIgIM3bsWPPQQw/56u7bt89cc801JjY21gwdOtSkpaWZN954oy+nOGB81SFojDE///nPzbRp00xnZ6cx5n8vAUyZMsWvXmNjo5FkJkyY0KPjMcaB7du3z9xwww1m1KhRJiIiwrhcLrN48WLT0tLiq7N//36Tk5NjYmJizKRJk0xlZaXfixrGGPP0008bl8tlhgwZctpX9m+77TYzderUgNuam5tNWFiY2bx5szHm+MdZMjIyjNPpNGeccYa54oorzKeffmqMMacdp4GoP663MScPwR07dhhJfh/xycrK6lZmjDGzZs0ykkxNTU2PznUgjTM/pQQAsBbPBAEA1iIEJW3YsEHDhg0LuEybNq2/u/eN0l/XmjEeOE42DsOGDVNNTU1/d+8bp7+u92AZZ26HSjp06JAOHDgQcFtERIQSExO/5h59c/XXtWaMB4733nvvpNvOOeecQfcRh4Guv673YBlnQhAAYC1uhwIArEUIAgCsRQgCAKxFCAIArEUIAgCsRQgCAKxFCAIArEUIAgCs9f8ADLKSbEtPhu8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (5, 3))\n",
    "plt.bar(metrics, values, width = 0.3)\n",
    "plt.ylim(0,0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bK_jyyEEtTUB"
   },
   "source": [
    "## Observation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlD_yx0cshJ7"
   },
   "source": [
    "- We find that both in case of training and testing data, the RNN model could not perform better than the Random Walk model which assumes that the best prediction is the previous observed value.\n",
    "- A surprising result though, is the improved accuracy of the model on testing data compared to training data - this is not common. However, this is no indication of a great model as the classifications are almost random!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFtrp-lmtw6t"
   },
   "source": [
    "## 4.) Creating a parameter for number of lags in the input layer. Running a 3-fold CV to test three different time lags of previous price data to forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#globally changing my training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.532144 using {'batch_size': 10, 'epochs': 5, 'input_size': 3} from original training data\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_size=4):\n",
    "    # Update training data with the best input size\n",
    "    global x_train_new\n",
    "    global y_train_new\n",
    "    \n",
    "    x_train_new = []\n",
    "    y_train_new = []\n",
    "    for i in range(input_size, len(train_data)):\n",
    "        x_train_new.append(train_data[i-input_size:i, 0])\n",
    "        y_train_new.append(np.where(train_data[i, 0] > 0, 1,0))\n",
    "\n",
    "    x_train_new, y_train_new = np.array(x_train_new), np.array(y_train_new)\n",
    "    x_train_new = np.reshape(x_train_new, (x_train_new.shape[0], x_train_new.shape[1], 1))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=False, input_shape=(input_size-1, 1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model in a scikit-learn compatible estimator\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "param_grid = {'batch_size': [10, 20, 100],\n",
    "              'epochs': [5, 10],\n",
    "              'input_size': [1,3, 5]}\n",
    "\n",
    "# Perform the grid search over the hyperparameters\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, scoring='accuracy')\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best accuracy: %f using %s from original training data\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the highest accuracy can be achieved with an input size of 3 lags, batch size of 10 samples and running the model with 5 epochs. This can be tuned further to test for higher epoch values but an accuracy of 53% is much higher than the original model. Further, accuracy may not be the best measure, we could try AUC and other metrics as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trial with above code +neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.532144 using {'batch_size': 10, 'epochs': 5, 'input_size': 3, 'neurons': 10} from original training data\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_size=4, neurons=30):\n",
    "    # Update training data with the best input size\n",
    "    global x_train_new\n",
    "    global y_train_new\n",
    "    \n",
    "    x_train_new = []\n",
    "    y_train_new = []\n",
    "    for i in range(input_size, len(train_data)):\n",
    "        x_train_new.append(train_data[i-input_size:i, 0])\n",
    "        y_train_new.append(np.where(train_data[i, 0] > 0, 1,0))\n",
    "\n",
    "    x_train_new, y_train_new = np.array(x_train_new), np.array(y_train_new)\n",
    "    x_train_new = np.reshape(x_train_new, (x_train_new.shape[0], x_train_new.shape[1], 1))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, return_sequences=False, input_shape=(input_size-1, 1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model in a scikit-learn compatible estimator\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "param_grid = {'batch_size': [10, 20, 100],\n",
    "              'epochs': [5, 10],\n",
    "              'input_size': [2,3, 5],\n",
    "             'neurons': [10,25,50]}\n",
    "\n",
    "# Perform the grid search over the hyperparameters\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, scoring='accuracy')\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best accuracy: %f using %s from original training data\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
